{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from eventdetector.util import get_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"london\": \"../data/output/mergestatslondon\",\n",
    "    \"ny\": \"../data/output/mergestatsny\",\n",
    "    \"baselondon\": \"../data/output/eventstatsbaselondon\",\n",
    "    \"baseny\": \"../data/output/eventstatsbaseny\",\n",
    "    \"embeddinglondon\": \"../data/output/eventstatsembeddinglondon\",\n",
    "    \"embeddingny\": \"../data/output/eventstatsembeddingny\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tops(dictionary, k, normalize=True):\n",
    "    keys = []\n",
    "    vals = []\n",
    "    \n",
    "    total = sum(dictionary.values())\n",
    "    \n",
    "    for key in dictionary:\n",
    "        keys.append(key)\n",
    "        if normalize:\n",
    "            vals.append(round(dictionary[key] / total, 4))\n",
    "        else:\n",
    "            vals.append(dictionary[key])\n",
    "\n",
    "    \n",
    "    top_vals, top_keys = get_top_k(vals, keys, k)\n",
    "    print(list(zip(top_vals, top_keys)))\n",
    "\n",
    "\n",
    "def print_data_stats(stats, kind):\n",
    "    print(\"Retweet \" + kind, stats[kind][\"rt\"])\n",
    "    print(\"Spam \" + kind, stats[kind][\"spam\"])\n",
    "    print(\"Not enough entity \" + kind, stats[kind][\"noentity\"])\n",
    "    print(\"Not enough token \" + kind, stats[kind][\"notoken\"])\n",
    "    print(\"Valid \" + kind, stats[kind][\"n\"])\n",
    "    \n",
    "    print(\"Top entity kinds \"+kind+\":\")\n",
    "    print_tops(stats[kind][\"kind\"], 20)\n",
    "    \n",
    "    \n",
    "def print_stats(stats):\n",
    "    print(\"-\"*10 + \" Data stats \" + \"-\"*10)\n",
    "    print(\"-\"*10 + \" Geo \" + \"-\"*10)\n",
    "    print_data_stats(stats, \"geo\")\n",
    "    print(\"-\"*10 + \" Non-geo \" + \"-\"*10)\n",
    "    print_data_stats(stats, \"nongeo\")\n",
    "    \n",
    "    print(\"-\"*10 + \" Clustering stats \" + \"-\"*10)\n",
    "    print(\"Total clusters:\", stats[\"n_clusters\"])\n",
    "    print(\"Bursting clusters:\", stats[\"n_bursting\"])\n",
    "    \n",
    "    print(\"-\"*10 + \" Performance stats \" + \"-\"*10)\n",
    "    mean_spam_time = stats[\"spam_time\"] / stats[\"spam_proc\"]\n",
    "    print(\"Mean spam time:\", mean_spam_time)\n",
    "    print(\"Total spam time:\", stats[\"spam_time\"])\n",
    "    \n",
    "    mean_spam_time = stats[\"ent_time\"] / stats[\"ent_proc\"]\n",
    "    print(\"Mean NER time:\", mean_spam_time)\n",
    "    print(\"Total NER time:\", stats[\"ent_time\"])\n",
    "\n",
    "    mean_ed_time = np.mean(stats[\"ed_bust_time\"] + stats[\"ed_norm_time\"])\n",
    "    print(\"Mean ed time:\", mean_ed_time)\n",
    "    total_ed_time = np.sum(stats[\"ed_bust_time\"] + stats[\"ed_norm_time\"])\n",
    "    print(\"Total ed time\", total_ed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_raw_stats(stats):\n",
    "    print(\"Geo count:\", stats[\"geo\"])\n",
    "    print(\"Nongeo count:\", stats[\"nongeo\"])\n",
    "    \n",
    "    print(\"Top sources geo:\")\n",
    "    print_tops(stats[\"geosource\"], 40, normalize=False)\n",
    "    print(\"Top sources nongeo:\")\n",
    "    print_tops(stats[\"nongeosource\"], 40, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"london\"], \"r\") as f:\n",
    "    stats_london = json.load(f)\n",
    "    \n",
    "with open(paths[\"ny\"], \"r\") as f:\n",
    "    stats_ny = json.load(f)\n",
    "\n",
    "with open(paths[\"baselondon\"], \"r\") as f:\n",
    "    stats_baselondon = json.load(f)\n",
    "\n",
    "with open(paths[\"baseny\"], \"r\") as f:\n",
    "    stats_baseny = json.load(f)\n",
    "\n",
    "with open(paths[\"embeddinglondon\"], \"r\") as f:\n",
    "    stats_emblondon = json.load(f)\n",
    "    \n",
    "with open(paths[\"embeddingny\"], \"r\") as f:\n",
    "    stats_embny = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_raw_stats(stats_london)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_raw_stats(stats_ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_stats(stats_baselondon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_stats(stats_baseny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(stats_emblondon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(stats_embny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_running_time(stats_london, stats_ny):\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    def plot(s, title, xlabel, ylabel):\n",
    "        plt.plot(range(len(s)), s)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    rolling = pd.Series(stats_london[\"ed_bust_time\"]).rolling(10).median()\n",
    "    plot(rolling, \"Burst Detection (London)\", \"# of Function Calls\", \"Time (seconds)\")\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    rolling = pd.Series(stats_london[\"ed_norm_time\"]).rolling(100).median()\n",
    "    plot(rolling, \"Sliding Window (London)\", \"# of Function Calls\", \"Time (seconds)\")\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    rolling = pd.Series(stats_ny[\"ed_bust_time\"]).rolling(10).median()\n",
    "    plot(rolling, \"Burst Detection (New York)\", \"# of Function Calls\", \"Time (seconds)\")\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    rolling = pd.Series(stats_ny[\"ed_norm_time\"]).rolling(100).median()\n",
    "    plot(rolling, \"Sliding Window (New York)\", \"# of Function Calls\", \"Time (seconds)\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_running_time(stats_baselondon, stats_baseny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_running_time(stats_emblondon, stats_embny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
